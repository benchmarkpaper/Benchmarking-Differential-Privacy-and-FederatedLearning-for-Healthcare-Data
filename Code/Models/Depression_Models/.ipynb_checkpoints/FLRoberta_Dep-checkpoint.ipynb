{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFcT_ttb3cxp",
    "outputId": "a4173f8c-1dae-4065-8c20-c264c19529a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==3.0.2 in /usr/local/lib/python3.7/dist-packages (3.0.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.41.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.19.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (20.9)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.0.45)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.95)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.0.12)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.8.1rc1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (2.4.7)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (8.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.0.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==3.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mI_AcZbA20Ll"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VGLPc0Pw4a_W"
   },
   "outputs": [],
   "source": [
    "# Setting up GPU\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i41lJQBIuEF-",
    "outputId": "58e37444-f776-40ea-d185-f38b7034d3be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "qm3GRXFa3Hbl",
    "outputId": "0991514b-ba21-4f13-927f-2e043c47bd10"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>tweet</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Today in Selfcare: beauty ; laughs Kung Fu Pan...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I get to spend New Year's home again alone and...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Depressed and lonely /: Stuck in a deep, never...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>If this is your response to someone saying the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Apparently you get a free pass just by mention...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              tweet  target\n",
       "0           0  Today in Selfcare: beauty ; laughs Kung Fu Pan...       0\n",
       "1           1  I get to spend New Year's home again alone and...       1\n",
       "2           2  Depressed and lonely /: Stuck in a deep, never...       1\n",
       "3           3  If this is your response to someone saying the...       0\n",
       "4           4  Apparently you get a free pass just by mention...       0"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/content/drive/My Drive/dep1_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YhlneiEHzB8"
   },
   "source": [
    "##Partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EGWafcsLH11y"
   },
   "source": [
    "###IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rPIyHBVTFifB"
   },
   "outputs": [],
   "source": [
    "def iid_partition(dataset, clients):\n",
    "  \"\"\"\n",
    "  I.I.D paritioning of data over clients\n",
    "  Shuffle the data\n",
    "  Split it between clients\n",
    "  \n",
    "  params:\n",
    "    - dataset (torch.utils.Dataset): Dataset containing the MNIST Images\n",
    "    - clients (int): Number of Clients to split the data between\n",
    "\n",
    "  returns:\n",
    "    - Dictionary of image indexes for each client\n",
    "  \"\"\"\n",
    "\n",
    "  num_items_per_client = int(len(dataset)/clients)\n",
    "  client_dict = {}\n",
    "  image_idxs = [i for i in range(len(dataset))]\n",
    "\n",
    "  for i in range(clients):\n",
    "    client_dict[i] = set(np.random.choice(image_idxs, num_items_per_client, replace=False))\n",
    "    image_idxs = list(set(image_idxs) - client_dict[i])\n",
    "\n",
    "  return client_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hhMk0QAH4kr"
   },
   "source": [
    "###Non-IID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "8Vr78-GMFm9p"
   },
   "outputs": [],
   "source": [
    "def non_iid_partition(dataset, clients, total_shards, shards_size, num_shards_per_client):\n",
    "  \"\"\"\n",
    "  non I.I.D parititioning of data over clients\n",
    "  Sort the data by the digit label\n",
    "  Divide the data into N shards of size S\n",
    "  Each of the clients will get X shards\n",
    "\n",
    "  params:\n",
    "    - dataset (torch.utils.Dataset): Dataset containing the MNIST Images\n",
    "    - clients (int): Number of Clients to split the data between\n",
    "    - total_shards (int): Number of shards to partition the data in\n",
    "    - shards_size (int): Size of each shard \n",
    "    - num_shards_per_client (int): Number of shards of size shards_size that each client receives\n",
    "\n",
    "  returns:\n",
    "    - Dictionary of image indexes for each client\n",
    "  \"\"\"\n",
    "  \n",
    "  shard_idxs = [i for i in range(total_shards)]\n",
    "  client_dict = {i: np.array([], dtype='int64') for i in range(clients)}\n",
    "  idxs = np.arange(len(dataset))\n",
    "  data_labels = dataset.get_labels()\n",
    "\n",
    "  # sort the labels\n",
    "  label_idxs = np.vstack((idxs, data_labels))\n",
    "  label_idxs = label_idxs[:, label_idxs[1,:].argsort()]\n",
    "  idxs = label_idxs[0,:]\n",
    "\n",
    "  # divide the data into total_shards of size shards_size\n",
    "  # assign num_shards_per_client to each client\n",
    "  for i in range(clients):\n",
    "    rand_set = set(np.random.choice(shard_idxs, num_shards_per_client, replace=False))\n",
    "    shard_idxs = list(set(shard_idxs) - rand_set)\n",
    "\n",
    "    for rand in rand_set:\n",
    "      client_dict[i] = np.concatenate((client_dict[i], idxs[rand*shards_size:(rand+1)*shards_size]), axis=0)\n",
    "  \n",
    "  return client_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oBavKNvISnMS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbYgMVAcTWXC"
   },
   "source": [
    "# MAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvHtHWHsT5E3"
   },
   "source": [
    "## MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lcqCzmTOh9N2"
   },
   "outputs": [],
   "source": [
    "#Base Roberta model\n",
    "class RobertaClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RobertaClass, self).__init__()\n",
    "        self.l1 = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "        self.classifier = torch.nn.Linear(768, 5)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A6srQnPth-4m",
    "outputId": "915977a9-b367-410a-e173-71c18539957a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaClass(\n",
       "  (l1): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RobertaClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eJYVU02b4DjQ"
   },
   "outputs": [],
   "source": [
    "#Initialization\n",
    "MAX_LEN = 256\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 2\n",
    "#EPOCHS = 10\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oOV8C2S54FXw"
   },
   "outputs": [],
   "source": [
    "class TweetData(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.text = dataframe.tweet\n",
    "        self.targets = self.data.target\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def get_labels(self):\n",
    "      l = []\n",
    "      for i in range(len(self.data)):\n",
    "        # text = str(self.text[i])\n",
    "        # text = \" \".join(text.split())\n",
    "\n",
    "        # inputs = self.tokenizer.encode_plus(\n",
    "        #     text,\n",
    "        #     None,\n",
    "        #     add_special_tokens=True,\n",
    "        #     max_length=self.max_len,\n",
    "        #     pad_to_max_length=True,\n",
    "        #     return_token_type_ids=True\n",
    "        # )\n",
    "\n",
    "        l.append(self.targets[i])\n",
    "\n",
    "      return l     \n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_eIAvHupTiBO"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "  def __init__(self, dataset, tokenizer, max_len, idxs):\n",
    "      self.data = dataset\n",
    "      self.idxs = list(idxs)\n",
    "      self.text = dataset.tweet\n",
    "      self.tokenizer = tokenizer\n",
    "      self.max_len = max_len\n",
    "      self.targets = self.data.target\n",
    "      \n",
    "  # def __init__(self, dataset, idxs):\n",
    "  #     self.dataset = dataset\n",
    "  #     self.idxs = list(idxs)\n",
    "\n",
    "  def __len__(self):\n",
    "      return len(self.idxs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "      text = str(self.text[index])\n",
    "      text = \" \".join(text.split())\n",
    "\n",
    "      inputs = self.tokenizer.encode_plus(\n",
    "          text,\n",
    "          None,\n",
    "          add_special_tokens=True,\n",
    "          max_length=self.max_len,\n",
    "          pad_to_max_length=True,\n",
    "          return_token_type_ids=True\n",
    "      )\n",
    "      ids = inputs['input_ids']\n",
    "      mask = inputs['attention_mask']\n",
    "      token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "\n",
    "      return {\n",
    "          'ids': torch.tensor(ids, dtype=torch.long),\n",
    "          'mask': torch.tensor(mask, dtype=torch.long),\n",
    "          'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
    "          'targets': torch.tensor(self.targets[index], dtype=torch.float)\n",
    "      }\n",
    "\n",
    "class ClientUpdate(object):\n",
    "  def __init__(self, dataset, model, tokenizer, loss_function, optimizer, idxs, epochs, MAX_LEN=256):\n",
    "    self.train_loader = DataLoader(CustomDataset(dataset, tokenizer, MAX_LEN, idxs), batch_size=8, shuffle=True)\n",
    "    self.model = model\n",
    "    self.loss_function = loss_function\n",
    "    self.optimizer = optimizer\n",
    "    self.epochs = epochs\n",
    "\n",
    "  # Function to calcuate the accuracy of the model\n",
    "\n",
    "  def calcuate_accu(self, big_idx, targets):\n",
    "    n_correct = (big_idx==targets).sum().item()\n",
    "    return n_correct\n",
    "\n",
    "  def train(self):\n",
    "\n",
    "    epochloss, epochacc = [], []\n",
    "    \n",
    "    for epoch in range(1, self.epochs+1):\n",
    "      tr_loss = 0\n",
    "      n_correct = 0\n",
    "      nb_tr_steps = 0\n",
    "      nb_tr_examples = 0\n",
    "      model.train()\n",
    "\n",
    "      for _,data in enumerate(self.train_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = self.model(ids, mask, token_type_ids)\n",
    "        loss = self.loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += self.calcuate_accu(big_idx, targets)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "        \n",
    "        if _%5000==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            accu_step = (n_correct*100)/nb_tr_examples \n",
    "            print(f\"Training Loss per 5000 steps: {loss_step}\")\n",
    "            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # # When using GPU\n",
    "        self.optimizer.step()\n",
    "\n",
    "      print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "      epoch_loss = tr_loss/nb_tr_steps\n",
    "      epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "      print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "      print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "      print(\"-------------------------------\")\n",
    "      epochloss.append(epoch_loss)\n",
    "      epochacc.append(epoch_accu)\n",
    "\n",
    "    return model.state_dict(), epochacc[-1], epochloss[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "NC6o9ggzVCNW"
   },
   "outputs": [],
   "source": [
    "def training(model, rounds, ds, data_dict, loss_function, lr, C, K, E,plt_color):\n",
    "  \"\"\"\n",
    "  Function implements the Federated Averaging Algorithm from the FedAvg paper.\n",
    "  Specifically, this function is used for the server side training and weight update\n",
    "\n",
    "  Params:\n",
    "    - model:           PyTorch model to train\n",
    "    - rounds:          Number of communication rounds for the client update\n",
    "    - batch_size:      Batch size for client update training\n",
    "    - lr:              Learning rate used for client update training\n",
    "    - ds:              Dataset used for training\n",
    "    - data_dict:       Type of data partition used for training (IID or non-IID)\n",
    "    - C:               Fraction of clients randomly chosen to perform computation on each round\n",
    "    - K:               Total number of clients\n",
    "    - E:               Number of training passes each client makes over its local dataset per round\n",
    "    - tb_writer_name:  Directory name to save the tensorboard logs\n",
    "  Returns:\n",
    "    - model:           Trained model on the server\n",
    "  \"\"\"\n",
    "\n",
    "  # global model weights\n",
    "  global_weights = model.state_dict()\n",
    "\n",
    "  # training loss\n",
    "  train_loss,train_acc = [], []\n",
    "\n",
    "  optimizer = torch.optim.Adam(params = model.parameters(), lr=lr)\n",
    "  \n",
    "  # measure time\n",
    "  start = time.time()\n",
    "\n",
    "  for curr_round in range(1, rounds+1):\n",
    "    w, local_loss,local_acc = [], [], []\n",
    "\n",
    "    m = max(int(C*K), 1)\n",
    "    \n",
    "    S_t = np.random.choice(range(K), m, replace=False)\n",
    "    for k in S_t:\n",
    "      local_update = ClientUpdate(dataset=ds, model=model, tokenizer=tokenizer, loss_function=loss_function, \\\n",
    "                                  optimizer=optimizer, epochs=E, idxs=data_dict[k])\n",
    "      weights, acc, loss = local_update.train()\n",
    "\n",
    "      w.append(copy.deepcopy(weights))\n",
    "      local_loss.append(copy.deepcopy(loss))\n",
    "      local_acc.append(copy.deepcopy(acc))\n",
    "\n",
    "    # updating the global weights\n",
    "    weights_avg = copy.deepcopy(w[0])\n",
    "    for k in weights_avg.keys():\n",
    "      for i in range(1, len(w)):\n",
    "        weights_avg[k] += w[i][k]\n",
    "\n",
    "      weights_avg[k] = torch.div(weights_avg[k], len(w))\n",
    "\n",
    "    global_weights = weights_avg\n",
    "\n",
    "    # move the updated weights to our model state dict\n",
    "    model.load_state_dict(global_weights)\n",
    "\n",
    "    # loss\n",
    "    loss_avg = sum(local_loss) / len(local_loss)\n",
    "    acc_avg = sum(local_acc) / len(local_acc)\n",
    "    print('Round: {}... \\tAverage Loss: {}'.format(curr_round, round(loss_avg, 3)))\n",
    "    print('Round: {}... \\tAverage Accuracy: {}'.format(curr_round, round(acc_avg, 3)))\n",
    "    train_loss.append(loss_avg)\n",
    "    train_acc.append(acc_avg)\n",
    "\n",
    "  end = time.time()\n",
    "  \n",
    "  fig, ax = plt.subplots()\n",
    "  x_axis = np.arange(1, rounds+1)\n",
    "  # y_axis = np.array(train_loss)\n",
    "  # ax.plot(x_axis, y_axis, 'tab:'+plt_color)\n",
    "\n",
    "  # ax.set(xlabel='Number of Rounds', ylabel='Train Loss',\n",
    "  #      title=\"Training Loss\")\n",
    "  \n",
    "  y_axis = np.array(train_acc)\n",
    "  ax.plot(x_axis, y_axis, 'tab:'+plt_color)\n",
    "\n",
    "  ax.set(xlabel='Number of Rounds', ylabel='Train Accuracy',\n",
    "       title=\"Training Accuracy vs. Global rounds\")\n",
    "  ax.grid()\n",
    "  #fig.savefig(plt_title+'.jpg', format='jpg')\n",
    "  print(\"Training Done!\")\n",
    "  print(\"Total time taken to Train: {}\".format(end-start))\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfPQekmI4JCv",
    "outputId": "cad77b10-0443-4f7f-fc95-bff1d5298516"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (3096, 3)\n",
      "TRAIN Dataset: (2477, 3)\n",
      "TEST Dataset: (619, 3)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset=df.sample(frac=train_size,random_state=200)\n",
    "test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = TweetData(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = TweetData(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "4DIl0v0P4Lss"
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zW4QTZ4Xtb9e",
    "outputId": "58379f95-4cd6-4cb3-a37c-c941fc884999"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 1.700748085975647\n",
      "Training Accuracy per 5000 steps: 0.0\n",
      "The Total Accuracy for Epoch 1: 51.012145748987855\n",
      "Training Loss Epoch: 1.3519107257166216\n",
      "Training Accuracy Epoch: 51.012145748987855\n",
      "-------------------------------\n",
      "Training Loss per 5000 steps: 0.8204828500747681\n",
      "Training Accuracy per 5000 steps: 75.0\n",
      "The Total Accuracy for Epoch 1: 75.30364372469636\n",
      "Training Loss Epoch: 0.6948380249161874\n",
      "Training Accuracy Epoch: 75.30364372469636\n",
      "-------------------------------\n",
      "Training Loss per 5000 steps: 0.777527391910553\n",
      "Training Accuracy per 5000 steps: 62.5\n",
      "The Total Accuracy for Epoch 1: 74.89878542510121\n",
      "Training Loss Epoch: 0.5783961482586399\n",
      "Training Accuracy Epoch: 74.89878542510121\n",
      "-------------------------------\n",
      "Round: 1... \tAverage Loss: 0.875\n",
      "Round: 1... \tAverage Accuracy: 67.072\n",
      "Training Loss per 5000 steps: 0.4711765944957733\n",
      "Training Accuracy per 5000 steps: 87.5\n",
      "The Total Accuracy for Epoch 1: 79.35222672064778\n",
      "Training Loss Epoch: 0.5321425891691639\n",
      "Training Accuracy Epoch: 79.35222672064778\n",
      "-------------------------------\n",
      "Training Loss per 5000 steps: 0.6431604027748108\n",
      "Training Accuracy per 5000 steps: 75.0\n",
      "The Total Accuracy for Epoch 1: 90.2834008097166\n",
      "Training Loss Epoch: 0.3145213086278208\n",
      "Training Accuracy Epoch: 90.2834008097166\n",
      "-------------------------------\n",
      "Training Loss per 5000 steps: 0.16210629045963287\n",
      "Training Accuracy per 5000 steps: 100.0\n",
      "The Total Accuracy for Epoch 1: 97.97570850202429\n",
      "Training Loss Epoch: 0.13244996652487787\n",
      "Training Accuracy Epoch: 97.97570850202429\n",
      "-------------------------------\n",
      "Round: 2... \tAverage Loss: 0.326\n",
      "Round: 2... \tAverage Accuracy: 89.204\n",
      "Training Loss per 5000 steps: 0.1107909306883812\n",
      "Training Accuracy per 5000 steps: 100.0\n",
      "The Total Accuracy for Epoch 1: 95.54655870445345\n",
      "Training Loss Epoch: 0.1492543657941203\n",
      "Training Accuracy Epoch: 95.54655870445345\n",
      "-------------------------------\n",
      "Training Loss per 5000 steps: 0.08418497443199158\n",
      "Training Accuracy per 5000 steps: 100.0\n",
      "The Total Accuracy for Epoch 1: 98.78542510121457\n",
      "Training Loss Epoch: 0.07465455326582154\n",
      "Training Accuracy Epoch: 98.78542510121457\n",
      "-------------------------------\n",
      "Training Loss per 5000 steps: 0.05619014427065849\n",
      "Training Accuracy per 5000 steps: 100.0\n",
      "The Total Accuracy for Epoch 1: 97.97570850202429\n",
      "Training Loss Epoch: 0.0683556557783196\n",
      "Training Accuracy Epoch: 97.97570850202429\n",
      "-------------------------------\n",
      "Round: 3... \tAverage Loss: 0.097\n",
      "Round: 3... \tAverage Accuracy: 97.436\n",
      "Training Done!\n",
      "Total time taken to Train: 131.9737741947174\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of training rounds\n",
    "rounds = 3\n",
    "# client fraction\n",
    "C = 0.3\n",
    "# number of clients\n",
    "K = 10\n",
    "# number of training passes on local dataset for each round\n",
    "E = 1\n",
    "# batch size\n",
    "batch_size = 10\n",
    "# learning Rate\n",
    "lr=1e-05\n",
    "# dict containing different type of data partition\n",
    "data_dict = iid_partition(training_set, 10)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  model.cuda()\n",
    "\n",
    "roberta_iid_trained = training(model, rounds, train_dataset, data_dict, loss_function, lr, C, K, E, \"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "c6TxASf-2aK5"
   },
   "outputs": [],
   "source": [
    "def calcuate_accuracy(big_idx, targets):\n",
    "  n_correct = (big_idx==targets).sum().item()\n",
    "  return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "KfihyQ6Btb7I"
   },
   "outputs": [],
   "source": [
    "#Testing the trained model\n",
    "\n",
    "def valid(model, testing_loader, loss_function):\n",
    "    model.eval()\n",
    "    n_correct = 0; n_wrong = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            outputs = model(ids, mask, token_type_ids)\n",
    "            loss = loss_function(outputs, targets)\n",
    "            tr_loss += loss.item()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            n_correct += calcuate_accuracy(big_idx, targets)\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=targets.size(0)\n",
    "            \n",
    "            if _%5000==0:\n",
    "                loss_step = tr_loss/nb_tr_steps\n",
    "                accu_step = (n_correct*100)/nb_tr_examples\n",
    "                print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
    "                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
    "    \n",
    "    return epoch_accu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DEWigxtmVCKn",
    "outputId": "9357ceb8-175a-43fb-d63e-f270f5ce1770"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 21.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the validation section to print the accuracy and see how it performs\n",
      "Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch\n",
      "Validation Loss per 100 steps: 2.3504159450531006\n",
      "Validation Accuracy per 100 steps: 50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [00:00, 21.53it/s]\u001b[A\n",
      "9it [00:00, 21.75it/s]\u001b[A\n",
      "12it [00:00, 22.05it/s]\u001b[A\n",
      "15it [00:00, 22.44it/s]\u001b[A\n",
      "18it [00:00, 22.80it/s]\u001b[A\n",
      "21it [00:00, 22.93it/s]\u001b[A\n",
      "24it [00:01, 23.09it/s]\u001b[A\n",
      "27it [00:01, 23.20it/s]\u001b[A\n",
      "30it [00:01, 23.24it/s]\u001b[A\n",
      "33it [00:01, 23.34it/s]\u001b[A\n",
      "36it [00:01, 23.31it/s]\u001b[A\n",
      "39it [00:01, 23.27it/s]\u001b[A\n",
      "42it [00:01, 23.32it/s]\u001b[A\n",
      "45it [00:01, 23.24it/s]\u001b[A\n",
      "48it [00:02, 23.19it/s]\u001b[A\n",
      "51it [00:02, 23.29it/s]\u001b[A\n",
      "54it [00:02, 23.45it/s]\u001b[A\n",
      "57it [00:02, 23.44it/s]\u001b[A\n",
      "60it [00:02, 23.49it/s]\u001b[A\n",
      "63it [00:02, 23.39it/s]\u001b[A\n",
      "66it [00:02, 23.48it/s]\u001b[A\n",
      "69it [00:02, 23.53it/s]\u001b[A\n",
      "72it [00:03, 23.49it/s]\u001b[A\n",
      "75it [00:03, 23.55it/s]\u001b[A\n",
      "78it [00:03, 23.56it/s]\u001b[A\n",
      "81it [00:03, 23.58it/s]\u001b[A\n",
      "84it [00:03, 23.63it/s]\u001b[A\n",
      "87it [00:03, 23.64it/s]\u001b[A\n",
      "90it [00:03, 23.45it/s]\u001b[A\n",
      "93it [00:04, 23.23it/s]\u001b[A\n",
      "96it [00:04, 23.15it/s]\u001b[A\n",
      "99it [00:04, 23.19it/s]\u001b[A\n",
      "102it [00:04, 23.19it/s]\u001b[A\n",
      "105it [00:04, 23.18it/s]\u001b[A\n",
      "108it [00:04, 23.14it/s]\u001b[A\n",
      "111it [00:04, 23.25it/s]\u001b[A\n",
      "114it [00:04, 23.32it/s]\u001b[A\n",
      "117it [00:05, 23.34it/s]\u001b[A\n",
      "120it [00:05, 23.42it/s]\u001b[A\n",
      "123it [00:05, 23.42it/s]\u001b[A\n",
      "126it [00:05, 23.52it/s]\u001b[A\n",
      "129it [00:05, 23.58it/s]\u001b[A\n",
      "132it [00:05, 23.54it/s]\u001b[A\n",
      "135it [00:05, 23.58it/s]\u001b[A\n",
      "138it [00:05, 23.64it/s]\u001b[A\n",
      "141it [00:06, 23.68it/s]\u001b[A\n",
      "144it [00:06, 23.70it/s]\u001b[A\n",
      "147it [00:06, 23.70it/s]\u001b[A\n",
      "150it [00:06, 23.69it/s]\u001b[A\n",
      "153it [00:06, 23.70it/s]\u001b[A\n",
      "156it [00:06, 23.67it/s]\u001b[A\n",
      "159it [00:06, 23.68it/s]\u001b[A\n",
      "162it [00:06, 23.68it/s]\u001b[A\n",
      "165it [00:07, 23.69it/s]\u001b[A\n",
      "168it [00:07, 23.70it/s]\u001b[A\n",
      "171it [00:07, 23.74it/s]\u001b[A\n",
      "174it [00:07, 23.76it/s]\u001b[A\n",
      "177it [00:07, 23.72it/s]\u001b[A\n",
      "180it [00:07, 23.57it/s]\u001b[A\n",
      "183it [00:07, 23.52it/s]\u001b[A\n",
      "186it [00:07, 23.60it/s]\u001b[A\n",
      "189it [00:08, 23.63it/s]\u001b[A\n",
      "192it [00:08, 23.69it/s]\u001b[A\n",
      "195it [00:08, 23.73it/s]\u001b[A\n",
      "198it [00:08, 23.72it/s]\u001b[A\n",
      "201it [00:08, 23.68it/s]\u001b[A\n",
      "204it [00:08, 23.62it/s]\u001b[A\n",
      "207it [00:08, 23.66it/s]\u001b[A\n",
      "210it [00:08, 23.47it/s]\u001b[A\n",
      "213it [00:09, 23.29it/s]\u001b[A\n",
      "216it [00:09, 23.40it/s]\u001b[A\n",
      "219it [00:09, 23.45it/s]\u001b[A\n",
      "222it [00:09, 23.52it/s]\u001b[A\n",
      "225it [00:09, 23.58it/s]\u001b[A\n",
      "228it [00:09, 23.59it/s]\u001b[A\n",
      "231it [00:09, 23.51it/s]\u001b[A\n",
      "234it [00:09, 23.37it/s]\u001b[A\n",
      "237it [00:10, 23.53it/s]\u001b[A\n",
      "240it [00:10, 23.41it/s]\u001b[A\n",
      "243it [00:10, 23.39it/s]\u001b[A\n",
      "246it [00:10, 23.31it/s]\u001b[A\n",
      "249it [00:10, 23.25it/s]\u001b[A\n",
      "252it [00:10, 23.31it/s]\u001b[A\n",
      "255it [00:10, 23.36it/s]\u001b[A\n",
      "258it [00:11, 23.33it/s]\u001b[A\n",
      "261it [00:11, 23.26it/s]\u001b[A\n",
      "264it [00:11, 23.13it/s]\u001b[A\n",
      "267it [00:11, 22.91it/s]\u001b[A\n",
      "270it [00:11, 22.93it/s]\u001b[A\n",
      "273it [00:11, 22.92it/s]\u001b[A\n",
      "276it [00:11, 22.80it/s]\u001b[A\n",
      "279it [00:11, 22.89it/s]\u001b[A\n",
      "282it [00:12, 22.91it/s]\u001b[A\n",
      "285it [00:12, 22.88it/s]\u001b[A\n",
      "288it [00:12, 22.96it/s]\u001b[A\n",
      "291it [00:12, 22.98it/s]\u001b[A\n",
      "294it [00:12, 23.08it/s]\u001b[A\n",
      "297it [00:12, 23.18it/s]\u001b[A\n",
      "300it [00:12, 22.99it/s]\u001b[A\n",
      "303it [00:12, 22.95it/s]\u001b[A\n",
      "306it [00:13, 23.00it/s]\u001b[A\n",
      "310it [00:13, 23.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss Epoch: 0.6231158756290472\n",
      "Validation Accuracy Epoch: 82.87560581583199\n",
      "Accuracy on test data = 82.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('This is the validation section to print the accuracy and see how it performs')\n",
    "print('Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch')\n",
    "\n",
    "acc = valid(roberta_iid_trained, testing_loader, loss_function)\n",
    "print(\"Accuracy on test data = %0.2f%%\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XAc_W8Yn0w8g",
    "outputId": "2e6d2542-a544-4ffc-93fd-20d73d7f4fdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.044888824224472046\n",
      "Training Accuracy per 5000 steps: 100.0\n",
      "The Total Accuracy for Epoch 1: 100.0\n",
      "Training Loss Epoch: 0.03427646724650493\n",
      "Training Accuracy Epoch: 100.0\n",
      "-------------------------------\n",
      "Training Loss per 5000 steps: 0.017738962545990944\n",
      "Training Accuracy per 5000 steps: 100.0\n",
      "The Total Accuracy for Epoch 1: 100.0\n",
      "Training Loss Epoch: 0.017072057638030786\n",
      "Training Accuracy Epoch: 100.0\n",
      "-------------------------------\n",
      "Training Loss per 5000 steps: 0.00947633571922779\n",
      "Training Accuracy per 5000 steps: 100.0\n",
      "The Total Accuracy for Epoch 1: 99.0\n",
      "Training Loss Epoch: 0.02355564020287532\n",
      "Training Accuracy Epoch: 99.0\n",
      "-------------------------------\n",
      "Round: 1... \tAverage Loss: 0.025\n",
      "Round: 1... \tAverage Accuracy: 99.667\n",
      "Training Loss per 5000 steps: 0.01257936842739582\n",
      "Training Accuracy per 5000 steps: 100.0\n",
      "The Total Accuracy for Epoch 1: 100.0\n",
      "Training Loss Epoch: 0.021539239929272577\n",
      "Training Accuracy Epoch: 100.0\n",
      "-------------------------------\n",
      "Training Loss per 5000 steps: 0.009828981943428516\n",
      "Training Accuracy per 5000 steps: 100.0\n",
      "The Total Accuracy for Epoch 1: 99.0\n",
      "Training Loss Epoch: 0.03381853647386798\n",
      "Training Accuracy Epoch: 99.0\n",
      "-------------------------------\n",
      "Training Loss per 5000 steps: 0.0151956956833601\n",
      "Training Accuracy per 5000 steps: 100.0\n",
      "The Total Accuracy for Epoch 1: 98.0\n",
      "Training Loss Epoch: 0.07670961216521952\n",
      "Training Accuracy Epoch: 98.0\n",
      "-------------------------------\n",
      "Round: 2... \tAverage Loss: 0.044\n",
      "Round: 2... \tAverage Accuracy: 99.0\n",
      "Training Loss per 5000 steps: 0.009510783478617668\n",
      "Training Accuracy per 5000 steps: 100.0\n",
      "The Total Accuracy for Epoch 1: 98.0\n",
      "Training Loss Epoch: 0.07845335457330713\n",
      "Training Accuracy Epoch: 98.0\n",
      "-------------------------------\n",
      "Training Loss per 5000 steps: 0.006718093529343605\n",
      "Training Accuracy per 5000 steps: 100.0\n",
      "The Total Accuracy for Epoch 1: 100.0\n",
      "Training Loss Epoch: 0.03058462844301875\n",
      "Training Accuracy Epoch: 100.0\n",
      "-------------------------------\n",
      "Training Loss per 5000 steps: 0.05705768242478371\n",
      "Training Accuracy per 5000 steps: 100.0\n",
      "The Total Accuracy for Epoch 1: 100.0\n",
      "Training Loss Epoch: 0.014383076045375604\n",
      "Training Accuracy Epoch: 100.0\n",
      "-------------------------------\n",
      "Round: 3... \tAverage Loss: 0.041\n",
      "Round: 3... \tAverage Accuracy: 99.333\n",
      "Training Done!\n",
      "Total time taken to Train: 53.838155031204224\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# number of training rounds\n",
    "rounds = 3\n",
    "# client fraction\n",
    "C = 0.3\n",
    "# number of clients\n",
    "K = 10\n",
    "# number of training passes on local dataset for each round\n",
    "E = 1\n",
    "# batch size\n",
    "batch_size = 10\n",
    "# learning Rate\n",
    "lr=1e-05\n",
    "# dict containing different type of data partition\n",
    "data_dict = non_iid_partition(training_set, 10, 240, 10, 10)\n",
    "#iid_partition(training_set, 10)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  model.cuda()\n",
    "\n",
    "roberta_non_iid_trained = training(model, rounds, train_dataset, data_dict, loss_function, lr, C, K, E, \"orange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oHxP3pkx5v-K",
    "outputId": "a76149fa-bf81-4876-a21a-1c2f9acdce80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "3it [00:00, 23.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the validation section to print the accuracy and see how it performs\n",
      "Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch\n",
      "Validation Loss per 100 steps: 0.0034762052819132805\n",
      "Validation Accuracy per 100 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "6it [00:00, 23.41it/s]\u001b[A\n",
      "9it [00:00, 23.41it/s]\u001b[A\n",
      "12it [00:00, 23.37it/s]\u001b[A\n",
      "15it [00:00, 23.36it/s]\u001b[A\n",
      "18it [00:00, 23.25it/s]\u001b[A\n",
      "21it [00:00, 23.35it/s]\u001b[A\n",
      "24it [00:01, 23.42it/s]\u001b[A\n",
      "27it [00:01, 23.46it/s]\u001b[A\n",
      "30it [00:01, 23.31it/s]\u001b[A\n",
      "33it [00:01, 23.44it/s]\u001b[A\n",
      "36it [00:01, 23.37it/s]\u001b[A\n",
      "39it [00:01, 23.17it/s]\u001b[A\n",
      "42it [00:01, 23.21it/s]\u001b[A\n",
      "45it [00:01, 23.33it/s]\u001b[A\n",
      "48it [00:02, 23.32it/s]\u001b[A\n",
      "51it [00:02, 23.31it/s]\u001b[A\n",
      "54it [00:02, 23.33it/s]\u001b[A\n",
      "57it [00:02, 23.28it/s]\u001b[A\n",
      "60it [00:02, 23.18it/s]\u001b[A\n",
      "63it [00:02, 23.20it/s]\u001b[A\n",
      "66it [00:02, 23.05it/s]\u001b[A\n",
      "69it [00:02, 23.02it/s]\u001b[A\n",
      "72it [00:03, 23.01it/s]\u001b[A\n",
      "75it [00:03, 23.07it/s]\u001b[A\n",
      "78it [00:03, 23.19it/s]\u001b[A\n",
      "81it [00:03, 23.32it/s]\u001b[A\n",
      "84it [00:03, 23.16it/s]\u001b[A\n",
      "87it [00:03, 23.09it/s]\u001b[A\n",
      "90it [00:03, 23.06it/s]\u001b[A\n",
      "93it [00:04, 23.02it/s]\u001b[A\n",
      "96it [00:04, 22.90it/s]\u001b[A\n",
      "99it [00:04, 23.03it/s]\u001b[A\n",
      "102it [00:04, 23.19it/s]\u001b[A\n",
      "105it [00:04, 23.33it/s]\u001b[A\n",
      "108it [00:04, 23.42it/s]\u001b[A\n",
      "111it [00:04, 23.41it/s]\u001b[A\n",
      "114it [00:04, 23.40it/s]\u001b[A\n",
      "117it [00:05, 23.25it/s]\u001b[A\n",
      "120it [00:05, 23.34it/s]\u001b[A\n",
      "123it [00:05, 23.45it/s]\u001b[A\n",
      "126it [00:05, 23.25it/s]\u001b[A\n",
      "129it [00:05, 23.24it/s]\u001b[A\n",
      "132it [00:05, 23.26it/s]\u001b[A\n",
      "135it [00:05, 23.18it/s]\u001b[A\n",
      "138it [00:05, 23.09it/s]\u001b[A\n",
      "141it [00:06, 23.08it/s]\u001b[A\n",
      "144it [00:06, 23.06it/s]\u001b[A\n",
      "147it [00:06, 22.82it/s]\u001b[A\n",
      "150it [00:06, 22.82it/s]\u001b[A\n",
      "153it [00:06, 22.58it/s]\u001b[A\n",
      "156it [00:06, 22.49it/s]\u001b[A\n",
      "159it [00:06, 22.78it/s]\u001b[A\n",
      "162it [00:06, 22.90it/s]\u001b[A\n",
      "165it [00:07, 23.11it/s]\u001b[A\n",
      "168it [00:07, 23.06it/s]\u001b[A\n",
      "171it [00:07, 23.05it/s]\u001b[A\n",
      "174it [00:07, 23.11it/s]\u001b[A\n",
      "177it [00:07, 23.22it/s]\u001b[A\n",
      "180it [00:07, 23.09it/s]\u001b[A\n",
      "183it [00:07, 23.18it/s]\u001b[A\n",
      "186it [00:08, 22.89it/s]\u001b[A\n",
      "189it [00:08, 22.68it/s]\u001b[A\n",
      "192it [00:08, 22.46it/s]\u001b[A\n",
      "195it [00:08, 22.55it/s]\u001b[A\n",
      "198it [00:08, 22.53it/s]\u001b[A\n",
      "201it [00:08, 22.48it/s]\u001b[A\n",
      "204it [00:08, 22.58it/s]\u001b[A\n",
      "207it [00:08, 22.59it/s]\u001b[A\n",
      "210it [00:09, 22.59it/s]\u001b[A\n",
      "213it [00:09, 22.74it/s]\u001b[A\n",
      "216it [00:09, 22.72it/s]\u001b[A\n",
      "219it [00:09, 22.70it/s]\u001b[A\n",
      "222it [00:09, 22.94it/s]\u001b[A\n",
      "225it [00:09, 23.06it/s]\u001b[A\n",
      "228it [00:09, 23.23it/s]\u001b[A\n",
      "231it [00:10, 23.31it/s]\u001b[A\n",
      "234it [00:10, 23.38it/s]\u001b[A\n",
      "237it [00:10, 23.43it/s]\u001b[A\n",
      "240it [00:10, 23.48it/s]\u001b[A\n",
      "243it [00:10, 23.22it/s]\u001b[A\n",
      "246it [00:10, 23.28it/s]\u001b[A\n",
      "249it [00:10, 23.15it/s]\u001b[A\n",
      "252it [00:10, 23.14it/s]\u001b[A\n",
      "255it [00:11, 23.00it/s]\u001b[A\n",
      "258it [00:11, 22.94it/s]\u001b[A\n",
      "261it [00:11, 23.02it/s]\u001b[A\n",
      "264it [00:11, 22.99it/s]\u001b[A\n",
      "267it [00:11, 23.17it/s]\u001b[A\n",
      "270it [00:11, 23.14it/s]\u001b[A\n",
      "273it [00:11, 23.24it/s]\u001b[A\n",
      "276it [00:11, 23.26it/s]\u001b[A\n",
      "279it [00:12, 23.16it/s]\u001b[A\n",
      "282it [00:12, 23.26it/s]\u001b[A\n",
      "285it [00:12, 23.21it/s]\u001b[A\n",
      "288it [00:12, 22.99it/s]\u001b[A\n",
      "291it [00:12, 23.14it/s]\u001b[A\n",
      "294it [00:12, 23.08it/s]\u001b[A\n",
      "297it [00:12, 23.06it/s]\u001b[A\n",
      "300it [00:12, 23.16it/s]\u001b[A\n",
      "303it [00:13, 23.15it/s]\u001b[A\n",
      "306it [00:13, 23.18it/s]\u001b[A\n",
      "310it [00:13, 23.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss Epoch: 0.7806281639540928\n",
      "Validation Accuracy Epoch: 83.03715670436188\n",
      "Accuracy on test data = 83.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('This is the validation section to print the accuracy and see how it performs')\n",
    "print('Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch')\n",
    "\n",
    "acc = valid(roberta_non_iid_trained, testing_loader, loss_function)\n",
    "print(\"Accuracy on test data = %0.2f%%\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUIsUxojzN0Q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FLRoberta_Dep.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
