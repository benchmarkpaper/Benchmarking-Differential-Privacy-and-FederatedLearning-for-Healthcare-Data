{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ALBERT_Pytorch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f4522bc2d77a4c5f82caf068bc49255c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_27434dda69ea46f2abad315e390d52a2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_99d6414ed7204c2895f9ebe01f6db4fc",
              "IPY_MODEL_58be502cc255438b93880e22c4915e34"
            ]
          }
        },
        "27434dda69ea46f2abad315e390d52a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99d6414ed7204c2895f9ebe01f6db4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8f0c8f7442a64b9a9bb20aab8b29e277",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 760289,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 760289,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17f3338997024b75bf813fa651c8b93e"
          }
        },
        "58be502cc255438b93880e22c4915e34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6eafd64ecf1546a298d65d8a493977ff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 760k/760k [00:06&lt;00:00, 126kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f2e68f0c6a73474d83c664fcc2e5775c"
          }
        },
        "8f0c8f7442a64b9a9bb20aab8b29e277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17f3338997024b75bf813fa651c8b93e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6eafd64ecf1546a298d65d8a493977ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f2e68f0c6a73474d83c664fcc2e5775c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAC33tfJDZhe",
        "outputId": "8f5a835b-db7f-4a5b-f638-c90e052e4c26"
      },
      "source": [
        "!pip install transformers==3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\r\u001b[K     |▍                               | 10kB 18.3MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 26.4MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 32.0MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 30.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 31.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 34.1MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 28.5MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81kB 29.9MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 31.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102kB 31.3MB/s eta 0:00:01\r\u001b[K     |████▊                           | 112kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 122kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 133kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 163kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 174kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 184kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 194kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 204kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 215kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 225kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 245kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 256kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 266kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 276kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 286kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 296kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 317kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 337kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 348kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 358kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 368kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 378kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 389kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 399kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 409kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 419kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 430kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 440kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 450kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 460kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 471kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 481kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 491kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 501kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 512kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 522kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 532kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 542kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 552kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 563kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 573kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 583kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 593kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 604kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 614kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 624kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 634kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 645kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 655kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 665kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 675kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 686kB 31.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 696kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 706kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 716kB 31.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 727kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 737kB 31.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 747kB 31.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 757kB 31.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/82/0e82a95bd9db2b32569500cc1bb47aa7c4e0f57aa5e35cceba414096917b/tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 49.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 45.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (20.9)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (8.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.95 tokenizers-0.8.0rc4 transformers-3.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZJAwfU3utMH"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "\n",
        "# Use GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "emUOZPJEutbw",
        "outputId": "40e9f973-1d12-4433-d9b3-7adcf8513f1a"
      },
      "source": [
        "df = pd.read_csv(\"dep1_cleaned.csv\")\n",
        "df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweet</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Today in Selfcare: beauty ; laughs Kung Fu Pan...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>I get to spend New Year's home again alone and...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Depressed and lonely /: Stuck in a deep, never...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>If this is your response to someone saying the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Apparently you get a free pass just by mention...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                              tweet  target\n",
              "0           0  Today in Selfcare: beauty ; laughs Kung Fu Pan...       0\n",
              "1           1  I get to spend New Year's home again alone and...       1\n",
              "2           2  Depressed and lonely /: Stuck in a deep, never...       1\n",
              "3           3  If this is your response to someone saying the...       0\n",
              "4           4  Apparently you get a free pass just by mention...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWOJmRUHxMf4",
        "outputId": "5a75ba97-8c0d-4863-95df-d6884bbbcea6"
      },
      "source": [
        "# Displaying Class distribution\n",
        "df['target'].value_counts(normalize = True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.728036\n",
              "1    0.271964\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbgSVMIyuxeA"
      },
      "source": [
        "train_text, temp_text, train_labels, temp_labels = train_test_split(df['tweet'], df['target'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.2, \n",
        "                                                                    stratify=df['target'])\n",
        "\n",
        "# Using temp_text and temp_labels to create validation and test set\n",
        "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "                                                                random_state=2018, \n",
        "                                                                test_size=0.1, \n",
        "                                                                stratify=temp_labels)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrIzvsJpu2UN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "f4522bc2d77a4c5f82caf068bc49255c",
            "27434dda69ea46f2abad315e390d52a2",
            "99d6414ed7204c2895f9ebe01f6db4fc",
            "58be502cc255438b93880e22c4915e34",
            "8f0c8f7442a64b9a9bb20aab8b29e277",
            "17f3338997024b75bf813fa651c8b93e",
            "6eafd64ecf1546a298d65d8a493977ff",
            "f2e68f0c6a73474d83c664fcc2e5775c"
          ]
        },
        "outputId": "75e3432d-751d-41dd-efed-10d6f68e8ed9"
      },
      "source": [
        "# Importing ALBERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('albert-base-v2')\n",
        "\n",
        "# Load the ALBERT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('albert-base-v2')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f4522bc2d77a4c5f82caf068bc49255c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDK7qeXcu5BG",
        "outputId": "827d0dae-e966-412c-84ab-ca56524bfc9b"
      },
      "source": [
        "# Sample data\n",
        "text = [\"this is a Albert model tutorial\", \"we will fine-tune a Albert model\"]\n",
        "\n",
        "# Encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)\n",
        "\n",
        "# Output\n",
        "print(sent_id)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [[2, 48, 25, 21, 2953, 1061, 29724, 3, 0, 0, 0], [2, 95, 129, 1123, 8, 38, 6763, 21, 2953, 1061, 3]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "d_Z0bPs_vHFc",
        "outputId": "30e06bd3-c9a5-4ec0-8940-41bdff6295d1"
      },
      "source": [
        "# Getting length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc7f092e610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nBjyeM7vMVy"
      },
      "source": [
        "max_seq_len = 25\n",
        "# Tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# Tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# Tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL6K2gNuvRc2"
      },
      "source": [
        "# Converting Integer Sequences to Tensor\n",
        "\n",
        "# For train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# For validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# For test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiHAXrtXvT9Z"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# Wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# Sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# DataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# Wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# Sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# DataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FapzQMuvWd5"
      },
      "source": [
        "# Freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcAr1VZ_vX7B"
      },
      "source": [
        "# Model Architecture\n",
        "\n",
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # Dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # Relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # Dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # Dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      # Softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    # Define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      # Pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # Output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # Apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oDoBoYdvay8"
      },
      "source": [
        "# Pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# Push the model to GPU\n",
        "model = model.to(device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDNCxGHnvdL1"
      },
      "source": [
        "# Optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmRnhX3Yv2Pc",
        "outputId": "4080edf0-e700-4e1c-e800-55c325ab24fd"
      },
      "source": [
        "# Finding class weights\n",
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Compute the class weights\n",
        "class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
        "\n",
        "print(class_wts)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.68663339 1.83952452]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tjhQmsGv4_e"
      },
      "source": [
        "# Convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# Loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# Number of training epochs\n",
        "epochs = 5\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywnd2bQav7mS"
      },
      "source": [
        "# Function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # Empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # Iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # Progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # Push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # Clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # Get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # Compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # Add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # Backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # Update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # Model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # Append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # Compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # Predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # Reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  # Returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcOBTYhzv-jh"
      },
      "source": [
        "# Function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # Deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # Empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # Iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # Push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # Deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # Model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # Compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # Compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # Reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkVkTfzrwEPc",
        "outputId": "8f4de1fd-7b41-486e-b5bd-1178cd33b8fa"
      },
      "source": [
        "# Set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# Empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "# For each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    # Train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    # Evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    # Save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # Append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 5\n",
            "  Batch    50  of     78.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.601\n",
            "Validation Loss: 0.522\n",
            "\n",
            " Epoch 2 / 5\n",
            "  Batch    50  of     78.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.587\n",
            "Validation Loss: 0.518\n",
            "\n",
            " Epoch 3 / 5\n",
            "  Batch    50  of     78.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.567\n",
            "Validation Loss: 0.510\n",
            "\n",
            " Epoch 4 / 5\n",
            "  Batch    50  of     78.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.535\n",
            "Validation Loss: 0.574\n",
            "\n",
            " Epoch 5 / 5\n",
            "  Batch    50  of     78.\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.564\n",
            "Validation Loss: 0.507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRxyA2YhwGxX",
        "outputId": "2c3d78d7-75e5-46e5-8dc3-fa18ca530ced"
      },
      "source": [
        "# Load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyilS2rAwWAJ"
      },
      "source": [
        "# Get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfnj-b-wwYyJ",
        "outputId": "c92b80fa-ca57-497e-e7f6-a55ccdd88963"
      },
      "source": [
        "# Model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.62      0.72        45\n",
            "           1       0.41      0.71      0.52        17\n",
            "\n",
            "    accuracy                           0.65        62\n",
            "   macro avg       0.63      0.66      0.62        62\n",
            "weighted avg       0.73      0.65      0.66        62\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "uLipc1l2wazm",
        "outputId": "4580cfca-d245-4a73-ef7d-0082f16e4aa9"
      },
      "source": [
        "# Confusion matrix\n",
        "pd.crosstab(test_y, preds)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>28</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0   0   1\n",
              "row_0        \n",
              "0      28  17\n",
              "1       5  12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrVOeQPIwdse",
        "outputId": "38606af2-6159-4ec6-d873-06f49abdac16"
      },
      "source": [
        "print (type(test_y))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'torch.Tensor'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFugKyQ0zx6r",
        "outputId": "10ea43ac-f621-4e78-f94d-9cfcdec1bb53"
      },
      "source": [
        "print (test_y)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE7trlzk1Dml",
        "outputId": "f0e3a7d1-d537-414e-c469-ce016fd1288c"
      },
      "source": [
        "testy_list = test_y.tolist()\n",
        "print (testy_list)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfMjbpax1yIb",
        "outputId": "711d6171-5a45-4001-db38-d920576074e7"
      },
      "source": [
        "preds_list = preds.tolist()\n",
        "print (preds_list)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOQ-kdB414o6",
        "outputId": "1b0ad3b8-0ffb-4f62-e46c-01e4806835e2"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "matrix = confusion_matrix(testy_list, preds_list)\n",
        "\n",
        "#Printing per class accuracy\n",
        "print (100*matrix.diagonal()/matrix.sum(axis=1))\n"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[62.22222222 70.58823529]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV30XrYH6Xhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0f3412-27a5-40b3-f8dc-5f804d35c1db"
      },
      "source": [
        "acc = accuracy_score(testy_list, preds_list)\n",
        "\n",
        "print(acc)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6451612903225806\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}