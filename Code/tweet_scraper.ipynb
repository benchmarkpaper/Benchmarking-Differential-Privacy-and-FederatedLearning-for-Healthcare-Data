{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/whopriyam/Desktop/Work/Depression-Detection-with-DP\n"
     ]
    }
   ],
   "source": [
    "path = os.path.abspath(os.getcwd())\n",
    "print (path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use your own Twitter developer credentials\n",
    "consumer_key = \"9DeRO6bnOOArrwBCJi3NUDySY\"\n",
    "consumer_secret = \"QCgi2aYhIgzfMw2xP4zEP3Sytq55SoZzWckr2btN9DaoWew2CL\"\n",
    "access_token = \"149872248-uDZHp3O7b50LpzDpt04p3qrQB4cnk77VmUEqUqHa\"\n",
    "access_token_secret = \"4UqLM0TDTUbP2w1X0kfFDJPUOX0vONd4ydttSBnECPEi5\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "def text_query_to_csv(text_query,count):\n",
    "    try:\n",
    "        # Creation of query method using parameters\n",
    "        tweets = tweepy.Cursor(api.search, q=text_query, lang='en', tweet_mode='extended').items(count)\n",
    "\n",
    "        # Pulling information from tweets iterable object\n",
    "        tweets_list = [[text_query, tweet.user.screen_name, tweet.id_str, tweet.created_at, tweet.favorite_count, tweet.geo, tweet.coordinates, tweet.full_text] for tweet in tweets]\n",
    "\n",
    "        # Creation of dataframe from tweets list\n",
    "        # Add or remove columns as you remove tweet information\n",
    "        tweets_df = pd.DataFrame(tweets_list,columns=['Key word', 'Username', 'User_ID', 'Datetime', 'Favorite_count', 'Geo', 'Coordinates', 'Text'])\n",
    "        tweets_df = tweets_df.drop_duplicates(subset='Text', keep='first')\n",
    "        # Converting dataframe to CSV \n",
    "        if tweets_df is not None:\n",
    "            print (len(tweets_df))\n",
    "        tweets_df.to_csv(path+'/scraped_tweets.csv', sep=',', index = False, mode = \"a\", header=None)\n",
    "        \n",
    "    except BaseException as e:\n",
    "        print('failed on_status,',str(e))\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalList2 = [\"depressed\", \"depression\", \"loneliness\", \"hopelessness\", \"suicide\", \"hopeless\", \"feel sad\", \"feeling sad\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_template = pd.DataFrame(columns = ['Key Word', 'Username', 'User_ID', 'Datetime', 'Favorite_count', 'Geo', 'Coordinates', 'Text'])\n",
    "# csv_template.to_csv(path+'/scraped_tweetss.csv', sep=',', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-21c47bb6354e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfinalList2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mtext_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinalList2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#Increment c value to scrape for each index keyword individually\n",
    "c = 8\n",
    "import time\n",
    "start=time.time()\n",
    "for i in range(c,c+1):\n",
    "  print (finalList2[i])\n",
    "  text_query = finalList2[i]\n",
    "  count = 500\n",
    "\n",
    "  text_query_to_csv(text_query, count)\n",
    "\n",
    "  c=c+1\n",
    "  print(c)\n",
    "\n",
    "print(time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
